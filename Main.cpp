#include <iostream>
#include <time.h>
#include "opencv2/core.hpp"
#include <opencv2/videoio.hpp>
#include "opencv2/highgui.hpp"
#include "opencv2/imgproc.hpp"
#include <opencv2/features2d.hpp>
#include "opencv2/flann.hpp"
#include "opencv2/calib3d.hpp"

#include <opencv2/xfeatures2d.hpp>

using namespace std;
using namespace cv;

const char* WIN_SAMPLE_NAME = "Sample Image";
const char* WIN_KEYPOINTS_NAME = "Keypoints";
const char* WIN_MATCHES_NAME = "Matches";
const char* WIN_SETTINGS_NAME = "Settings";
const char* WIN_AUGMENTATION_NAME = "Augmentation";

bool TEST_MODE = false; // whether all the parameters be shown

bool value_changed = false; // whether user change parameter at current frame

char  input_img_paths[2][256]; // path for input images

Mat img_in[2];
Mat img_sample; // gray version of sample image to match in frame
Mat img_prep; // sample image after preprocessing
Mat img_target; // augmented image onto matching instance
Mat img_keypoints, img_matches; // images for each intemediare step
Mat frame, frame_gray; // realtime webcam frame and gray image
Mat img_homography; // perspective transformation of target image
Mat img_overlay; // overlay image of homography with frame
Mat frame_augmented; // final frame with augmented image, with effect of opacity

Mat descriptors_sample, descriptors_frame; // descriptors generated by chosen detector

/* CLAHE parameters */
const char* tile_grid_size_name = "CLAHE size";
Ptr<CLAHE> clahe;
int tile_grid_size_max_value = 10;
int tile_grid_size_value = 1;

/* Gaussian Blurring parameters, the real value will be divided by 10 */
const char* gaussian_sigma_name = "Std Devia";
int sigma_max_value = 40;
int sigma_value = 10;

vector<KeyPoint> keypoints_sample, keypoints_frame; // keypoints list from sample image and frame

vector<Point2f> points_sample;
vector<Point2f> points_frame;

vector<Point2f> corners_sample(4); // the four corners of sample image

VideoCapture cap;

vector<float> percentage; // for evaluation of solution
float average; // for evaluation of solution

/* SIFT parameters */
int 	nfeatures = 0;
int 	nOctaveLayers_sift = 3;
double 	contrastThreshold = 0.04;
double 	edgeThreshold = 10;
double 	sigma = 1.6;

/* SURF parameters */
double 	hessianThreshold = 100;
int 	nOctaves_surf = 4;
int 	nOctaveLayers = 3;

/* BRISK parameters */
int 	threshold_brisk = 15;
int 	octaves_brisk = 4;
float 	pattern_scale = 1.0f;

/* pointers to feature extractor */
Ptr<AKAZE> akaze;
Ptr<ORB> orb;
Ptr<SIFT> sift;
Ptr<BRISK> brisk;
Ptr<xfeatures2d::SURF> surf;
Ptr<Feature2D> curr_KPDetector;

/* BRISK tarckbar */
const char* threshold_name = "Threshold";
const char* octaves_name = "Octaves";
const char* pattern_scale_name = "Pattern";

int threshold_max_value = 100;
int octaves_max_value = 8;
int pattern_scale_value = 10;
int pattern_scale_max_value = 30;

/* Keypoint detector trackbar */
const char* KPDetector_name = "KPDetector";
int KPDetector_max_value = 4;
int KPDetector_id = 4;

Ptr<Feature2D> setKPDetector(int id)
{
	switch (id) {
	case 0:
	default:
		KPDetector_name = "SURF";
		return surf;
	case 1:
		KPDetector_name = "SIFT";
		return sift;
	case 2:
		KPDetector_name = "ORB";
		return orb;
	case 3:
		KPDetector_name = "AKAZE";
		return akaze;
	case 4:
		KPDetector_name = "BRISK";
		return brisk;
	}
}

/* pointers to Descriptor Matcher */
Ptr<BFMatcher> BFL1_matcher;       // - BruteForce (L1 norm)
Ptr<BFMatcher> BFL2_matcher;       // - BruteForce (L2 norm)
Ptr<BFMatcher> BFHamming_matcher;  // - BruteForce-Hamming
Ptr<FlannBasedMatcher> FLANN_based_matcher; // - FLANN based
Ptr<DescriptorMatcher> curr_descriptor_matcher;

bool crossCheck = false; // matcher crossCheck

/* Descriptor Matcher trackbar */
const char* descriptor_matcher_name = "Matcher";
int descriptor_matcher_max_value = 3;
int descriptor_matcher_id = 3;

Ptr<DescriptorMatcher> setDescriptorMatcher(int id)
{
	switch (id) {
	case 0:
	default:
		descriptor_matcher_name = "FLANN based";
		return FLANN_based_matcher;
	case 1:
		descriptor_matcher_name = "BruteForce (L1 norm)";
		return BFL1_matcher;
	case 2:
		descriptor_matcher_name = "BruteForce (L2 norm)";
		return BFL2_matcher;
	case 3:
		descriptor_matcher_name = "BruteForce-Hamming"; // suitable for ORB, AKAZE, BRISK
		return BFHamming_matcher;
	}
}

int k = 2; // k nearest neighbor
size_t num_matches;
size_t num_good_matches;
vector<DMatch> matches;
vector<vector<DMatch>> knn_matches;

/* Matches Filter trackbar */
const char* matches_filter_name = "Filter";
int matches_filter_max_value = 1;
int matches_filter_id = 1;

/* ratio trackbar */
const char* matches_filter_ratio_name = "Ratio";
int matches_filter_ratio_max_value = 100;
int matches_filter_ratio_value = 70;
// ratio threshold
// 1. KNN -- rate for comparing the distances between each nearest-neighbor matches.
// 2. Score -- rate for retaining those matches with higher scores

void matchesFilter(int id, float ratio)
{
	switch (id)
	{
	case 0:
	default:
	{
		/* reference: OpenCV-VideoKeypointMatching.cpp by Nicolas ROUGON */
		matches_filter_name = "Best matching & Score filtering";
		crossCheck = true;
		curr_descriptor_matcher->match(descriptors_sample, descriptors_frame, matches);

		num_matches = matches.size();
		num_good_matches = (size_t)(num_matches * ratio);
		// Sort matches by score
		sort(matches.begin(), matches.end());
		// Filter out matches with large scores
		matches.erase(matches.begin() + num_good_matches, matches.end());
	}
	break;
	case 1:
		/* reference: https://docs.opencv.org/3.4/d7/dff/tutorial_feature_homography.html */
		matches_filter_name = "KNN matching & Ratio filtering";
		crossCheck = false;
		curr_descriptor_matcher->knnMatch(descriptors_sample, descriptors_frame, knn_matches, k);

		for (size_t i = 0; i < knn_matches.size(); i++)
		{
			if (knn_matches[i][0].distance < ratio * knn_matches[i][1].distance)
			{
				matches.push_back(knn_matches[i][0]);
			}
		}
		break;
	}
}

/* Opacity of Augmented image */
const char* opacity_name = "Opacity";
int opacity_max_value = 255;
int opacity_value = 255;

// signature of functions
void parseInput(int argc, char* argv[]); // convert input images
void init();
void createGUI(); // create trackbars to modify parameters
void update();
void callback(int value, void* userdata); // callback when parameters are modified
Mat overlay_image_bgr(Mat in_frame, Mat in_target);
void clearVectors(); // release space of pointers and list created
void calculateAverage();
int usage(char* prgname);

int main(int argc, char* argv[])
{
	parseInput(argc, argv);
	init();

	createGUI();
	callback(0, 0);

	while (true)
	{
		update();
		clearVectors();
		value_changed = false;

		if (waitKey(30) >= 0)
			break;
	}

	destroyAllWindows();

	return 0;
}

void parseInput(int argc, char* argv[])
{
	/* reference: OpenCV-ImageDisplay by Nicolas ROUGON */
	// this simple parser could only load two images -- target image & sample image
	if (argc >= 2 * 2 + 1)
		for (int i = 1; i < argc; i++) {
			if (!strcmp(argv[i], "-i")) {
				if (++i > argc)
					usage(argv[0]);
				sprintf(input_img_paths[(i / 2) - 1], "%s", argv[i]);
			}
			else {
				cout << "!!! Invalid program option !!!" << argv[i] << endl;
				usage(argv[0]);
			}
		}
	else
	{
		cout << "!!! Missing argument !!!" << endl;
		usage(argv[0]);
	}

	/* store input images into the image array */
	for (int i = 0; i < 2; i++) {
		// Load image
		img_in[i] = imread(input_img_paths[i], IMREAD_UNCHANGED);
		if (img_in[i].empty()) {
			cout << "!!! Cannot read the image " << input_img_paths[i] << " !!!" << endl;
			break;
		}
	}

	cvtColor(img_in[0], img_sample, COLOR_BGR2GRAY);
	img_target = img_in[1];
}
void init()
{
	/* webcam input */
	cap.open(0);
	cap >> frame;

	/* preprocessing */
	clahe = createCLAHE();

	/* resize the target image to be the same as frame's size */
	resize(img_target, img_target, frame.size(), 0, 0, 0);

	/* Keypoint Detector pointers creation */
	akaze = AKAZE::create();
	orb = ORB::create();
	sift = SIFT::create(nfeatures, nOctaveLayers_sift, contrastThreshold, edgeThreshold, sigma);
	brisk = BRISK::create(threshold_brisk, octaves_brisk, pattern_scale);
	surf = xfeatures2d::SURF::create(hessianThreshold, nOctaves_surf, nOctaveLayers);

	/* Descriptor Matcher pointers creation */
	BFL1_matcher = BFMatcher::create(NORM_L1, crossCheck);
	BFL2_matcher = BFMatcher::create(NORM_L2, crossCheck);
	BFHamming_matcher = BFMatcher::create(NORM_HAMMING, crossCheck);
	FLANN_based_matcher = FlannBasedMatcher::create();
}

void createGUI()
{
	/* put all parameters into settings window */
	namedWindow(WIN_SETTINGS_NAME, WINDOW_AUTOSIZE);

	/* preprocessing */
	createTrackbar(tile_grid_size_name, WIN_SETTINGS_NAME, &tile_grid_size_value,
		tile_grid_size_max_value, (TrackbarCallback)callback);
	createTrackbar(gaussian_sigma_name, WIN_SETTINGS_NAME, &sigma_value,
		sigma_max_value, (TrackbarCallback)callback);

	/* if not in test mode, show only the optimal solution's parameters */
	if (TEST_MODE)
	{
		/* Keypoint Detector */
		createTrackbar(KPDetector_name, WIN_SETTINGS_NAME, &KPDetector_id,
			KPDetector_max_value, (TrackbarCallback)callback);
		/* Descriptor Matcher */
		createTrackbar(descriptor_matcher_name, WIN_SETTINGS_NAME, &descriptor_matcher_id,
			descriptor_matcher_max_value, (TrackbarCallback)callback);
	}
	/* BRISK parameters */
	createTrackbar(threshold_name, WIN_SETTINGS_NAME, &threshold_brisk,
		threshold_max_value, (TrackbarCallback)callback);
	createTrackbar(octaves_name, WIN_SETTINGS_NAME, &octaves_brisk,
		octaves_max_value, (TrackbarCallback)callback);
	createTrackbar(pattern_scale_name, WIN_SETTINGS_NAME, &pattern_scale_value,
		pattern_scale_max_value, (TrackbarCallback)callback);

	/* Matches Filter */
	createTrackbar(matches_filter_name, WIN_SETTINGS_NAME, &matches_filter_id,
		matches_filter_max_value, (TrackbarCallback)callback);
	/* Matches Filter Rate */
	createTrackbar(matches_filter_ratio_name, WIN_SETTINGS_NAME, &matches_filter_ratio_value,
		matches_filter_ratio_max_value, (TrackbarCallback)callback);
	/* Opacity */
	createTrackbar(opacity_name, WIN_SETTINGS_NAME, &opacity_value,
		opacity_max_value, (TrackbarCallback)callback);
}

void update()
{
	/* update webcam input */
	cap >> frame;
	cvtColor(frame, frame_gray, COLOR_BGR2GRAY);

	/* Preprocessing: CLAHE & Gaussian Blurring */
	clahe->apply(img_sample, img_prep);
	GaussianBlur(img_prep, img_prep, Size(0, 0), sigma_value / 10, sigma_value / 10);

	/* KPDetector extraction */
	curr_KPDetector->detectAndCompute(img_prep, noArray(), keypoints_sample, descriptors_sample);
	curr_KPDetector->detectAndCompute(frame_gray, noArray(), keypoints_frame, descriptors_frame);

	/* descriptor matching && matches filtering */
	matchesFilter(matches_filter_id, (float)matches_filter_ratio_value / matches_filter_ratio_max_value);

	/* reference: https://docs.opencv.org/3.4/d7/dff/tutorial_feature_homography.html */
	/* push into list of points that are in matches of sample image and frame */
	for (size_t i = 0; i < matches.size(); i++)
	{
		points_sample.push_back(keypoints_sample[matches[i].queryIdx].pt);
		points_frame.push_back(keypoints_frame[matches[i].trainIdx].pt);
	}

	/* four corners of sample image as point */
	corners_sample[0] = Point2f(0, 0);
	corners_sample[1] = Point2f((float)img_prep.cols, 0);
	corners_sample[2] = Point2f((float)img_prep.cols, (float)img_prep.rows);
	corners_sample[3] = Point2f(0, (float)img_prep.rows);

	/* perspective transformation of matching points */
	if (points_sample.size() != 0 && points_frame.size() != 0)
	{
		// calculate the perspective transformation
		Mat H = findHomography(points_sample, points_frame, RANSAC);

		if (!H.empty())
		{
			warpPerspective(img_target, img_homography, H, img_homography.size(), 0);

			// blend target image with frame
			double alpha = (double)opacity_value / (double)opacity_max_value;
			double beta = 1 - alpha;
			addWeighted(img_homography, alpha, frame, beta, 0.0, img_overlay);

			frame_augmented = overlay_image_bgr(frame, img_overlay);
		}
		else
		{
			frame_augmented = frame;
		}
	}

	/* show result */
	/* if the parameter is changed, the image will not be shown at this frame */
	if (!value_changed)
	{
		imshow(WIN_SAMPLE_NAME, img_sample);
		drawKeypoints(img_prep, keypoints_sample, img_keypoints, Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);

		if (matches.size() > 0)
		{
			drawMatches(img_prep, keypoints_sample, frame_gray, keypoints_frame, matches, img_matches, Scalar::all(-1),
				Scalar::all(-1), vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
			imshow(WIN_SETTINGS_NAME, img_matches);
			imshow(WIN_AUGMENTATION_NAME, frame_augmented);
		}

		imshow(WIN_KEYPOINTS_NAME, img_keypoints);
	}
}

void callback(int value, void* userdata)
{
	cout << "------------------------------------------------------------------------------" << endl;

	clahe->setTilesGridSize(Size(tile_grid_size_value, tile_grid_size_value));
	cout << "> Grid Size          | " << tile_grid_size_value << endl;

	cout << "> Standard Deviation | " << sigma_value / 10 << endl;

	curr_KPDetector = setKPDetector(KPDetector_id);
	cout << "> Keypoints Detector | " << KPDetector_name << endl;

	pattern_scale = (float)pattern_scale_value / 10;
	brisk = BRISK::create(threshold_brisk, octaves_brisk, pattern_scale);
	cout << "> Threshold          | " << threshold_brisk << endl;
	cout << "> Octaves            | " << octaves_brisk << endl;
	cout << "> Pattern Scale      | " << pattern_scale << endl;

	curr_descriptor_matcher = setDescriptorMatcher(descriptor_matcher_id);
	cout << "> Descriptor Matcher | " << descriptor_matcher_name << endl;

	matchesFilter(matches_filter_id, (float)matches_filter_ratio_value / matches_filter_ratio_max_value);
	cout << "> Matches Filtering  | " << matches_filter_name << endl;
	cout << "> Matches Rate       | " << (float)matches_filter_ratio_value / matches_filter_ratio_max_value << endl;

	value_changed = true;
}

Mat overlay_image_bgr(Mat in_frame, Mat in_target)
{
	Mat out = in_frame;
	int    i, j;
	int    nrows = in_frame.rows;
	int    ncols = in_frame.cols;
	int    nchannels_in = in_frame.channels();

	for (j = 0; j < nrows; j++) {
		for (i = 0; i < ncols; i++) {
			if (in_target.at<Vec3b>(j, i)[0] > 0)
			{
				out.at<Vec3b>(j, i)[0] = in_target.at<Vec3b>(j, i)[0];
				out.at<Vec3b>(j, i)[1] = in_target.at<Vec3b>(j, i)[1];
				out.at<Vec3b>(j, i)[2] = in_target.at<Vec3b>(j, i)[2];
			}
		}
	}
	return out;
}

void clearVectors()
{
	keypoints_sample.clear();
	keypoints_frame.clear();

	matches.clear();
	for (int i = 0; i < knn_matches.size(); i++)
	{
		knn_matches[i].clear();
	}
	knn_matches.clear();

	points_frame.clear();
	points_sample.clear();
	corners_sample.clear();
}

int usage(char* prgname)
{
	cout << "This program should load " << 2 << " images as input" << endl;
	cout << "Usage: " << prgname << " ";
	cout << "[-i {image file}]" << endl;
	exit(-1);
}

//--------------------------------Test Functions ---------------------------------------------//

void matchesFilteringTest()
{
	clock_t t;
	t = clock();
	printf("%s descriptors matching took me %d clocks (%f seconds).\n", KPDetector_name, t, ((float)t) / CLOCKS_PER_SEC);
	printf("current matcher is %s.\n", descriptor_matcher_name);
	if (descriptor_matcher_id != 0)
	{
		if (crossCheck)
			cout << "cross check: True " << endl;
		else
			cout << "cross check: False" << endl;
	}
	printf("matching filter is %s.\n", matches_filter_name);
	printf("keypoints1 numbers: %d.\n", (int)keypoints_sample.size());
	printf("keypoints2 numbers: %d.\n", (int)keypoints_frame.size());
	printf("matching numbers: %d.\n", (int)matches.size());
	printf("matching rate: %f.\n", (float)matches.size() / keypoints_sample.size());
	percentage.push_back((float)matches.size() / (float)keypoints_sample.size());
}

void KPTests()
{
	clock_t t;
	t = clock();
	printf("Calculating...\n");

	surf->detect(img_sample, keypoints_sample);

	t = clock() - t;
	printf("surf took me %d clocks (%f seconds).\n", t, ((float)t) / CLOCKS_PER_SEC);
	printf("keypoints numbers: %d.\n", (int)keypoints_sample.size());

	sift->detect(img_sample, keypoints_sample);

	t = clock() - t;
	printf("sift took me %d clocks (%f seconds).\n", t, ((float)t) / CLOCKS_PER_SEC);
	printf("keypoints numbers: %d.\n", (int)keypoints_sample.size());

	orb->detect(img_sample, keypoints_sample);

	t = clock() - t;
	printf("orb took me %d clocks (%f seconds).\n", t, ((float)t) / CLOCKS_PER_SEC);
	printf("keypoints numbers: %d.\n", (int)keypoints_sample.size());

	akaze->detect(img_sample, keypoints_sample);

	t = clock() - t;
	printf("akaze took me %d clocks (%f seconds).\n", t, ((float)t) / CLOCKS_PER_SEC);
	printf("keypoints numbers: %d.\n", (int)keypoints_sample.size());

	brisk->detect(img_sample, keypoints_sample);

	t = clock() - t;
	printf("brisk took me %d clocks (%f seconds).\n", t, ((float)t) / CLOCKS_PER_SEC);
	printf("keypoints numbers: %d.\n", (int)keypoints_sample.size());

	drawKeypoints(img_sample, keypoints_sample, img_keypoints, Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);
	imshow(WIN_KEYPOINTS_NAME, img_keypoints);
}

void KPParamsTest()
{
	printf("nfeatures: %d.\n", nfeatures);
	printf("nOtavesLayers: %d.\n", nOctaveLayers_sift);
	printf("contrast threshold: %f. \n", (float)contrastThreshold);
	printf("edge threshold: %f. \n", (float)edgeThreshold);
	printf("sigma: %f. \n", (float)sigma);

	printf("threshold: %d.\n", threshold_brisk);
	printf("Otaves: %d.\n", octaves_brisk);
	printf("pattern scale: %f. \n", pattern_scale);
}

void calculateAverage()
{
	float total = 0;
	for (int i = 0; i < percentage.size(); i++)
	{
		total += percentage[i];
	}
	average = total / percentage.size();
	printf("average rate: %f\n", average);
}

void matchTest()
{
	clock_t t;
	t = clock();

	/* descriptor matching */
	//matchesFilter(matches_filter_id);

	t = clock() - t;
	printf("%s descriptors matching took me %d clocks (%f seconds).\n", KPDetector_name, t, ((float)t) / CLOCKS_PER_SEC);
	printf("The matcher is %s.\n", descriptor_matcher_name);
	printf("The matcher filter is %s.\n", matches_filter_name);
	printf("keypoints1 numbers: %d.\n", (int)keypoints_sample.size());
	printf("keypoints2 numbers: %d.\n", (int)keypoints_frame.size());
	printf("matching numbers: %d.\n", (int)matches.size());
	printf("matching rate: %f.\n", (float)matches.size() / keypoints_frame.size());
	percentage.push_back((float)matches.size() / (float)keypoints_frame.size());
}

//-----------------------------------------------------------------------------